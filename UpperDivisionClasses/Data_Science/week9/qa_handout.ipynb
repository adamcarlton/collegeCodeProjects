{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "a3cb0ee3-7bca-4b2b-8a27-be198d18818e",
    "_uuid": "075ab0f3fc310e293828b3681f1d80642f88c106"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".h1_cell, .just_text {\n",
       "    box-sizing: border-box;\n",
       "    padding-top:5px;\n",
       "    padding-bottom:5px;\n",
       "    font-family: \"Times New Roman\", Georgia, Serif;\n",
       "    font-size: 125%;\n",
       "    line-height: 22px; /* 5px +12px + 5px */\n",
       "    text-indent: 25px;\n",
       "    background-color: #fbfbea;\n",
       "    padding: 10px;\n",
       "}\n",
       "\n",
       "hr { \n",
       "    display: block;\n",
       "    margin-top: 0.5em;\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "    border-style: inset;\n",
       "    border-width: 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".h1_cell, .just_text {\n",
    "    box-sizing: border-box;\n",
    "    padding-top:5px;\n",
    "    padding-bottom:5px;\n",
    "    font-family: \"Times New Roman\", Georgia, Serif;\n",
    "    font-size: 125%;\n",
    "    line-height: 22px; /* 5px +12px + 5px */\n",
    "    text-indent: 25px;\n",
    "    background-color: #fbfbea;\n",
    "    padding: 10px;\n",
    "}\n",
    "\n",
    "hr { \n",
    "    display: block;\n",
    "    margin-top: 0.5em;\n",
    "    margin-bottom: 0.5em;\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "    border-style: inset;\n",
    "    border-width: 2px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>\n",
    "<center>\n",
    "Module 9\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Last week we explored how to pull relation triples out of a sentence. This week, let's see if we can do something with those triples.\n",
    "<p>\n",
    "Your goal is to store the relations you extract from sentences in a \"knowledge base\". My first thought was to use a pandas dataframe as the knowledge base. Store a relation one per row with 3 columns. But I don't think that is a good idea. Two of the three values are NP subtrees. The subtrees can have structure of their own, e.g., more than one leaf node. I don't see how to easily store the subtree in a dataframe.\n",
    "<p>\n",
    "Maybe the easiest is to implement the knoweldge base as just a list of relations, where each relation is a triple of NP verb NP.\n",
    "<p>\n",
    "Before we get going, here is some material from last week as reference.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.\tCC\tCoordinating conjunction\n",
    "2.\tCD\tCardinal number\n",
    "3.\tDT\tDeterminer\n",
    "4.\tEX\tExistential there\n",
    "5.\tFW\tForeign word\n",
    "6.\tIN\tPreposition or subordinating conjunction\n",
    "7.\tJJ\tAdjective\n",
    "8.\tJJR\tAdjective, comparative\n",
    "9.\tJJS\tAdjective, superlative\n",
    "10.\tLS\tList item marker\n",
    "11.\tMD\tModal\n",
    "12.\tNN\tNoun, singular or mass\n",
    "13.\tNNS\tNoun, plural\n",
    "14.\tNNP\tProper noun, singular\n",
    "15.\tNNPS\tProper noun, plural\n",
    "16.\tPDT\tPredeterminer\n",
    "17.\tPOS\tPossessive ending\n",
    "18.\tPRP\tPersonal pronoun\n",
    "19.\tPRP$\tPossessive pronoun\n",
    "20.\tRB\tAdverb\n",
    "21.\tRBR\tAdverb, comparative\n",
    "22.\tRBS\tAdverb, superlative\n",
    "23.\tRP\tParticle\n",
    "24.\tSYM\tSymbol\n",
    "25.\tTO\tto\n",
    "26.\tUH\tInterjection\n",
    "27.\tVB\tVerb, base form\n",
    "28.\tVBD\tVerb, past tense\n",
    "29.\tVBG\tVerb, gerund or present participle\n",
    "30.\tVBN\tVerb, past participle\n",
    "31.\tVBP\tVerb, non-3rd person singular present\n",
    "32.\tVBZ\tVerb, 3rd person singular present\n",
    "33.\tWDT\tWh-determiner\n",
    "34.\tWP\tWh-pronoun\n",
    "35.\tWP$\tPossessive wh-pronoun\n",
    "36.\tWRB\tWh-adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Victor Frankenstein builds the creature in his laboratory',\n",
    "\n",
    "    'The creature is 8 feet tall',  # tricky\n",
    "\n",
    "    'the monster wanders through the wilderness',  # tricky\n",
    "\n",
    "    'He finds brief solace beside a remote cottage inhabited by a family of peasants',\n",
    "\n",
    "    'Eavesdropping, the creature familiarizes himself with their lives and learns to speak',  # tricky\n",
    "\n",
    "    \"The creature eventually introduces himself to the family's blind father\",\n",
    "\n",
    "    'the creature rescues a peasant girl from a river.',\n",
    "\n",
    "    \"He finds Frankenstein's journal in the pocket of the jacket he found in the laboratory\",\n",
    "\n",
    "    \"The monster kills Victor's younger brother William upon learning of the boy's relation to his hated creator.\",\n",
    "\n",
    "    \"Frankenstein builds a female creature.\",\n",
    "\n",
    "    \"the monster kills Frankenstein's best friend Henry Clerva.\",\n",
    "\n",
    "    \"the monster boards the ship.\",\n",
    "\n",
    "    \"The monster has also been analogized to an oppressed class\",\n",
    "\n",
    "    \"the monster is the tragic result of uncontrolled technology.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_relation(text, chunker):\n",
    "    \n",
    "    #chunk the text with chunker\n",
    "    chunks = chunker.parse(nltk.pos_tag(nltk.word_tokenize(text)))\n",
    "    \n",
    "    #Now re-chunk looking for our triples. Call the chunk REL for relation\n",
    "    chunker2 = nltk.RegexpParser(r'''\n",
    "                   REL:\n",
    "                   {<NP><VBZ><NP>}\n",
    "                   ''')\n",
    "    relation_chunk = chunker2.parse(chunks)\n",
    "    \n",
    "    for t in relation_chunk:\n",
    "        if type(t) != Tree: continue\n",
    "        if t.label() == 'REL':\n",
    "            return (t[0], t[1], t[2])\n",
    "            \n",
    "    return tuple([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_chunker2 = nltk.RegexpParser(r'''\n",
    "    NP:\n",
    "    {<DT>?<JJ>*<NN>} # chunk determiner (optional), adjectives (optional) and noun\n",
    "    {<NNP>+} # chunk sequences of proper nouns\n",
    "    {<NNP>*<NNP>}\n",
    "    {<NNPP><VBZ><NNP>}\n",
    "    {<VBZ><.*>*?<NN>}\n",
    "    {<PRP>|<NNP>*<PRP>|<NNP>}\n",
    "    {<NNP><CD>*<NN>}\n",
    "    {<PRP>*<VBZ><JJ>}\n",
    "    {<CD><NNS><JJ>}\n",
    "    {<RB>?<VBN>*<TO>}\n",
    "    {<RB>}\n",
    "   ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tree('NP', [('Victor', 'NNP'), ('Frankenstein', 'NNP')]),\n",
       " ('builds', 'VBZ'),\n",
       " Tree('NP', [('the', 'DT'), ('creature', 'NN')]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_relation(sentences[0], rel_chunker2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "All the sentences\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "See how many we can pull relations from. I am showing results prior to your assignment. I assume you now are seeing less empty tuples, i.e., you are matching more sentences.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tree('NP', [('Victor', 'NNP'), ('Frankenstein', 'NNP')]), ('builds', 'VBZ'), Tree('NP', [('the', 'DT'), ('creature', 'NN')]))\n",
      "===============\n",
      "(Tree('NP', [('The', 'DT'), ('creature', 'NN')]), ('is', 'VBZ'), Tree('NP', [('8', 'CD'), ('feet', 'NNS'), ('tall', 'JJ')]))\n",
      "===============\n",
      "()\n",
      "===============\n",
      "()\n",
      "===============\n",
      "(Tree('NP', [('the', 'DT'), ('creature', 'NN')]), ('familiarizes', 'VBZ'), Tree('NP', [('himself', 'PRP')]))\n",
      "===============\n",
      "(Tree('NP', [('eventually', 'RB')]), ('introduces', 'VBZ'), Tree('NP', [('himself', 'PRP')]))\n",
      "===============\n",
      "(Tree('NP', [('the', 'DT'), ('creature', 'NN')]), ('rescues', 'VBZ'), Tree('NP', [('a', 'DT'), ('peasant', 'JJ'), ('girl', 'NN')]))\n",
      "===============\n",
      "(Tree('NP', [('He', 'PRP')]), ('finds', 'VBZ'), Tree('NP', [('Frankenstein', 'NNP')]))\n",
      "===============\n",
      "(Tree('NP', [('The', 'DT'), ('monster', 'NN')]), ('kills', 'VBZ'), Tree('NP', [('Victor', 'NNP')]))\n",
      "===============\n",
      "(Tree('NP', [('Frankenstein', 'NNP')]), ('builds', 'VBZ'), Tree('NP', [('a', 'DT'), ('female', 'JJ'), ('creature', 'NN')]))\n",
      "===============\n",
      "(Tree('NP', [('the', 'DT'), ('monster', 'NN')]), ('kills', 'VBZ'), Tree('NP', [('Frankenstein', 'NNP')]))\n",
      "===============\n",
      "()\n",
      "===============\n",
      "(Tree('NP', [('The', 'DT'), ('monster', 'NN')]), ('has', 'VBZ'), Tree('NP', [('also', 'RB'), ('been', 'VBN'), ('analogized', 'VBN'), ('to', 'TO')]))\n",
      "===============\n",
      "(Tree('NP', [('the', 'DT'), ('monster', 'NN')]), ('is', 'VBZ'), Tree('NP', [('the', 'DT'), ('tragic', 'JJ'), ('result', 'NN')]))\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "all_relations = []  # will be our knowledge base\n",
    "for i,s in enumerate(sentences):\n",
    "    relation = build_relation(s, rel_chunker2)\n",
    "    all_relations.append(relation)\n",
    "    print(relation)\n",
    "    print('===============')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>\n",
    "Challenge 1\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "The goal will be to write a lookup query that looks like \"Show me who built things.\". Or \"Who did the monster kill?\"\n",
    "Your first thought might be that this is straightforward. Just match \"built\" or \"kill\" to the verb in each relation using `==`. But the actual verbs are \"builds\" and \"kills\". So won't literally match.\n",
    "<p>\n",
    "There is something we can use to help. It is called a lemmatizer and nltk has one (actually several). The general idea is that we pass any form of a verb in like \"build\" and it will always return \"build\". Let's check it out.\n",
    "<p>\n",
    "<p>\n",
    "BTW: WordNet is kind of interesting. It is an online syllabus of a huge number of English words. It is separate from nltk. However, nltk has a wrapper for it so we can use it as below.\n",
    "<p>\n",
    "BTW2: for the spelling police out there, see this:\n",
    "<pre>\n",
    "builded. Verb. (archaic or childish, nonstandard) simple past tense and past participle of build.\n",
    "</pre>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer  # using the cool WordNet syllabus\n",
    "lemmatizer = WordNetLemmatizer()  # one of the varietes to choose from in nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\n",
      "build\n",
      "build\n",
      "build\n",
      "builted\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"build\", pos=\"v\"))\n",
    "print(lemmatizer.lemmatize(\"builds\", pos=\"v\"))\n",
    "print(lemmatizer.lemmatize(\"built\", pos=\"v\"))\n",
    "print(lemmatizer.lemmatize(\"builded\", pos=\"v\"))  # archaic but ok\n",
    "print(lemmatizer.lemmatize(\"builted\", pos=\"v\"))  # bogus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Here are a few more, nouns if no pos parameter.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "best\n",
      "ran\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(lemmatizer.lemmatize(\"cats\"))  # default to n or noun\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))  # a is adjective\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"ran\"))\n",
    "print(lemmatizer.lemmatize(\"ran\",'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "I think we are in business. If we are trying to match one form of the same verb against another, we can lemmatize both of them first then use `==`. We are almost ready to define a function, verb_match, that takes a verb we are trying to match and a relation we are matching against. It returns True if we get a match after lemmatization. But before that, let's look at a relation in a bit more detail.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tree('NP', [('Victor', 'NNP'), ('Frankenstein', 'NNP')]), ('builds', 'VBZ'), Tree('NP', [('the', 'DT'), ('creature', 'NN')]))\n"
     ]
    }
   ],
   "source": [
    "s0 = all_relations[0]  # first relation in our knowledge base\n",
    "print(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tree('NP', [('Victor', 'NNP'), ('Frankenstein', 'NNP')]), <class 'nltk.tree.Tree'>)\n",
      "(('builds', 'VBZ'), <type 'tuple'>)\n",
      "(Tree('NP', [('the', 'DT'), ('creature', 'NN')]), <class 'nltk.tree.Tree'>)\n"
     ]
    }
   ],
   "source": [
    "for item in s0:\n",
    "    print((item, type(item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "You can see that the relation is a triple of (Tree, tuple, Tree). Since we are only focusing on the verb, we don't have to deal with Tree objects yet. That will come when we want to match against noun-phrases (1st and 3rd components of the triple).\n",
    "<p>\n",
    "We can see that the verb is a tuple of actual verb and then its pos as seen in table above. With that info, you should be ready to define the function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verb_match(verb_word, relation):\n",
    "    try:\n",
    "        verbLem = lemmatizer.lemmatize(verb_word, pos=\"v\")\n",
    "        relLem = lemmatizer.lemmatize(relation[1][0], pos=\"v\")\n",
    "    except:\n",
    "        return False\n",
    "    return verbLem == relLem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(verb_match('built', s0))\n",
    "print(verb_match('build', s0))\n",
    "print(verb_match('builds', s0))\n",
    "print(verb_match('builts', s0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Challenge 2\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Cool. We have verb matching under control. Now for matching a noun-phrase. A noun-phrase as we have defined it is a Tree object with one or more leaves. A leaf is a tuple of word followed by pos. Before doing anything else, let's define a helper function that will return a list of the words on the leaves.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_word_list(np_tree):\n",
    "    leaves = np_tree.leaves()  # Tree method\n",
    "    return [tup[0] for tup in leaves]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "You can see I am using a method leaves() that is defined by the Tree class. It will give us a list of tuples. I then use a list comprehension to pull out the words.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tree('NP', [('Victor', 'NNP'), ('Frankenstein', 'NNP')]), <class 'nltk.tree.Tree'>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Victor', 'Frankenstein']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np1 = s0[0]  # first noun-phrase\n",
    "print((np1, type(np1)))\n",
    "np_to_word_list(np1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'creature']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np2 = s0[2]  # second noun-phrase\n",
    "np_to_word_list(np2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Matching strategy\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We know we can get a list of words from a noun-phrase. We could easily check for a single word match by using the `in` operator, e.g., 'a' in ['b', 'a', 'c'] returns True. I'd like something a bit more sophisticated. I would like the match words to also be a list. So we are attempting to match a list of words against another list of words. How does this work? Let's call the two word lists target-words and np-words. I would like you to go through each word in target-words, one by one, and find a match in np-words. The tricky part is I would like you to remember where the match occurred in np-words and start the next match from that point. Here are some examples. First list is target-words and second np-words.\n",
    "<pre>\n",
    "\n",
    "['a', 'b', 'c'] and ['d', 'a', 'b', 'r', 'c', 'f'] match.\n",
    "\n",
    "['a', 'b', 'c'] and ['d', 'a', 'c', 'r', 'b', 'f'] no match.\n",
    "\n",
    "['a', 'b', 'c'] and ['d', 'a', 'b', 'r', 'b', 'f'] no match.\n",
    "\n",
    "[] and ['d', 'a', 'b', 'r', 'b', 'f'] wildcard match.\n",
    "\n",
    "</pre>\n",
    "\n",
    "Also see the example calls below the function definition.\n",
    "<p>\n",
    "BTW: I broke out single word matching into a separate function. I did so to make it easier to do more sophisticated matching in the future.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_word_match(word1, word2):\n",
    "    word1 = word1.lower()\n",
    "    word2 = word2.lower()\n",
    "    \n",
    "    #literally equal\n",
    "    return word1 == word2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assisted by Meg Fredericks\n",
    "def np_match(np_tree, target_word_list):\n",
    "    indeces = []\n",
    "    np_word_list = np_to_word_list(np_tree)\n",
    "    for word in target_word_list:\n",
    "        for i in range(len(np_word_list)):\n",
    "            if np_word_match(word, np_word_list[i]):\n",
    "                indeces.append(i)\n",
    "    return all(i<j for i,j in zip(indeces, indeces[1:])) and len(indeces) == len(target_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_match(s0[0], ['victor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_match(s0[0], ['victor', 'frankenstein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_match(s0[0], [ 'frankenstein', 'victor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_match(s0[0], ['victor', 'victor', 'frankenstein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_match(s0[2], ['the', 'creature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_match(s0[2], [])  # empty list is wildcard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Should we lemmatize matching?\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "At moment, np_word_match is matching words literally. But we saw for verbs, lemmatization helped as be less strict and match different forms of same verb. How would that work with words in noun phrases? Here is an example:\n",
    "<pre>\n",
    "(Tree('NP', [('Frankenstein', 'NNP')]), ('builds', 'VBZ'), Tree('NP', [('a', 'DT'), ('female', 'JJ'), ('creature', 'NN')]))\n",
    "</pre>\n",
    "<p>\n",
    "It sounds reasonable to me to match women with female. Will the lemmatizer give us this?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"woman\",'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"female\",'n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Nope. I think we are going to have to try something else. Let's consider a thesaurus based approach. We can get the synonyms of a word and check against that. So if we are trying to match word1 against word2, we could also match word1 against the synonyms of word2 and vice versa. Does nltk give us a thesaurus to use? Yes. More accurately, it gives us access to that large online thesaurus called WordNet. Here is a function that will return the synonyms of a word using WordNet.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syns(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lem in syn.lemmas():\n",
    "            synonyms.append(lem.name())\n",
    "    return list(set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'distaff', u'female_person', u'female']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_syns('female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cleaning_woman',\n",
       " u'woman',\n",
       " u'womanhood',\n",
       " u'fair_sex',\n",
       " u'cleaning_lady',\n",
       " u'char',\n",
       " u'adult_female',\n",
       " u'charwoman']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_syns('woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Uh. A little on the sexist side if you ask me. And does not give us what we want: a match between 'female' and 'woman': 'female' does not appear in synonyms for 'woman' nor vice versa. Let's check some others.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ogre',\n",
       " u'giant',\n",
       " u'devil',\n",
       " u'freak',\n",
       " u'monster',\n",
       " u'behemoth',\n",
       " u'teras',\n",
       " u'colossus',\n",
       " u'demon',\n",
       " u'fiend',\n",
       " u'monstrosity',\n",
       " u'lusus_naturae',\n",
       " u'goliath']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_syns('monster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'animate_being',\n",
       " u'tool',\n",
       " u'brute',\n",
       " u'beast',\n",
       " u'wight',\n",
       " u'puppet',\n",
       " u'animal',\n",
       " u'fauna',\n",
       " u'creature']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_syns('creature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Still no luck. But looking at some of the synonyms, it does open the door to matching 'monster' with useful synonyms and same for 'creature'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ogre' in get_syns('monster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'brute' in get_syns('creature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Challenge 3\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Go ahead and modify np_word_match to now include a match against synonym lists. As before return True if literal match. But also return True if word1 in synonyms of word2 or vice versa.\n",
    "<p>\n",
    "My guess is you only need to check against one synonym list because of symmetry of synonyms. In particular, my hypothesis is that if you don't find word1 in synonyms of word2, you won't find word2 in synonyms of word1. But I have not had a chance to verify this so check against both lists for now.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#improved version\n",
    "\n",
    "def np_word_match(word1, word2):\n",
    "    word1 = word1.lower()\n",
    "    word2 = word2.lower()\n",
    "    if word1 == word2:\n",
    "        return True\n",
    "    word1Syns = get_syns(word1)\n",
    "    word2Syns = get_syns(word2)\n",
    "    if word1 in word2Syns or word2 in word1Syns:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_match(s0[2], ['brute'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Challenge 4\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Ok, now we have some helper functions defined and we can get to the cool stuff. I want to treat our collection of relations as a kind of database (I'll also sometimes use the more high falutin term *knowledge base*). What can you do with a database? You can query it. I'd like you to build the function `who` to get us started. The function will take 3 arguments: (1) the verb to match on, (2) a list of words to match against the 2nd noun-phrase, and (3) the relation to check.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One more helper function if you need it\n",
    "def np_to_string(np_tree):\n",
    "    words = np_to_word_list(np_tree)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who(verb, target_words, relation):\n",
    "    if len(relation) == 0:\n",
    "        return None\n",
    "    if verb_match(verb, relation) and np_match(relation[2], target_words):\n",
    "        return np_to_string(relation[0])\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victor Frankenstein\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for rel in all_relations:\n",
    "    print(who('built', ['the', 'creature'], rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "the creature\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for rel in all_relations:\n",
    "    print(who('rescued', ['girl'], rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "the monster\n"
     ]
    }
   ],
   "source": [
    "for rel in all_relations:\n",
    "    print(who('was', ['tragic'], rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "The monster\n",
      "None\n",
      "the monster\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for rel in all_relations:\n",
    "    print(who('killed', [], rel))  # use of wildcard: Who killed anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "I'm going to package up the for loop into a function. I'll return a list of answers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_who(verb, target_words, kb):\n",
    "    who_dunit = []\n",
    "    for rel in kb:\n",
    "        if not rel: continue\n",
    "        p = who(verb, target_words, rel)\n",
    "        if p: who_dunit.append(p)\n",
    "    return who_dunit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Victor Frankenstein']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_who('built', ['the', 'creature'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Victor Frankenstein']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_who('built', ['the', 'brute'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the creature']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_who('rescued', ['girl'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the monster']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_who('killed', ['frankenstein'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the monster']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_who('was', ['tragic'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The monster', 'the monster']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_who('killed', [], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_who('built', ['the', 'monster'], all_relations)  #seems like it should match but does not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Challenge 5\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Pretty dang cool if you ask me. Let's do another. Define `what_done_by` that only takes 2 arguments: (1) the list of target words to match against the first noun-phrase and (2) the relation. See my example results below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_done_by(target_words, relation):\n",
    "    if np_match(relation[0], target_words):\n",
    "        return relation[1][0] + ' ' + np_to_string(relation[2]) \n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_what_done_by(target_words, kb):\n",
    "    what_done = []\n",
    "    for rel in kb:\n",
    "        if not rel: continue\n",
    "        p = what_done_by(target_words, rel)\n",
    "        if p: what_done.append(p)\n",
    "    return what_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['builds the creature']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_what_done_by(['victor'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kills Victor',\n",
       " 'kills Frankenstein',\n",
       " 'has also been analogized to',\n",
       " 'is the tragic result']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_what_done_by(['monster'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['builds the creature',\n",
       " 'is 8 feet tall',\n",
       " 'familiarizes himself',\n",
       " 'introduces himself',\n",
       " 'rescues a peasant girl',\n",
       " 'finds Frankenstein',\n",
       " 'kills Victor',\n",
       " 'builds a female creature',\n",
       " 'kills Frankenstein',\n",
       " 'has also been analogized to',\n",
       " 'is the tragic result']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_what_done_by([], all_relations)  # wildcard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Challenge 6\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Last one. Define a function `what_happened_to` that takes target words to match against the 2nd noun-phrase.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_happened_to(target_words, relation):\n",
    "    if np_match(relation[2], target_words):\n",
    "        return np_to_string(relation[0]) + ' ' + relation[1][0] + ' ' + np_to_string(relation[2])\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_what_happened_to(target_words, kb):\n",
    "    what_done_to = []\n",
    "    for rel in kb:\n",
    "        if not rel: continue\n",
    "        p = what_happened_to(target_words, rel)\n",
    "        if p: what_done_to.append(p)\n",
    "    return what_done_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Victor Frankenstein builds the creature',\n",
       " 'Frankenstein builds a female creature']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_what_happened_to(['creature'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Victor Frankenstein builds the creature',\n",
       " 'Frankenstein builds a female creature']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_what_happened_to(['brute'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the creature rescues a peasant girl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_what_happened_to(['tyke'], all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Victor Frankenstein builds the creature',\n",
       " 'The creature is 8 feet tall',\n",
       " 'the creature familiarizes himself',\n",
       " 'eventually introduces himself',\n",
       " 'the creature rescues a peasant girl',\n",
       " 'He finds Frankenstein',\n",
       " 'The monster kills Victor',\n",
       " 'Frankenstein builds a female creature',\n",
       " 'the monster kills Frankenstein',\n",
       " 'The monster has also been analogized to',\n",
       " 'the monster is the tragic result']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_for_what_happened_to([], all_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Closing Notes\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "One next step would be to build something closer to an SQL language for querying. Then map that language to our functions.\n",
    "<p>\n",
    "Another step would be to look for contradictions, e.g., \"X killed Y\", \"Y killed X\". Or \"X is 8 feet tall\", \"X is 3 feet tall\". One of our PhD students just finished a study like this for medical papers. He tried to find contradictions in different author's findings. And he did! He wrote to the authors and pointed out the contractions. You might even be able to use it to detect fake news. If (a big if) you had a set of relations that you knew were true, you can search the web for text (e.g., tweets, blogs) that contradicted what you knew was true.\n",
    "<p>\n",
    "A never-ending next step is to improve pattern-matching to extract relations. Deal with the convoluted way English sentences can be written.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
